#!/usr/bin/env python3
"""
A2AI (Advanced Financial Analysis AI) Database Setup Script
ä¼æ¥­ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«åˆ†æå¯¾å¿œãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–

Features:
- 150ç¤¾ã®ä¼æ¥­ãƒã‚¹ã‚¿ãƒ¼ç®¡ç†
- 40å¹´åˆ†ã®è²¡å‹™è«¸è¡¨ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
- ä¼æ¥­æ¶ˆæ»…ãƒ»æ–°è¨­ãƒ»åˆ†ç¤¾ã‚¤ãƒ™ãƒ³ãƒˆç®¡ç†
- 9ã¤ã®è©•ä¾¡é …ç›® Ã— 23ã®è¦å› é …ç›®å¯¾å¿œ
- å¸‚å ´ã‚·ã‚§ã‚¢ãƒ‡ãƒ¼ã‚¿ç®¡ç†
- ç”Ÿå­˜ãƒã‚¤ã‚¢ã‚¹è£œæ­£ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
"""

import os
import sys
import logging
from datetime import datetime, date
from pathlib import Path
import sqlite3
import pandas as pd
from typing import Optional, List, Dict, Any

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from config.settings import DATABASE_CONFIG, LOGGING_CONFIG
from src.utils.logging_utils import setup_logger

class A2AIDatabaseSetup:
    """A2AI ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, db_path: Optional[str] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯è¨­å®šå€¤ã‚’ä½¿ç”¨ï¼‰
        """
        self.logger = setup_logger(__name__, LOGGING_CONFIG)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹è¨­å®š
        if db_path is None:
            db_path = DATABASE_CONFIG.get('path', 'data/a2ai_database.db')
        
        self.db_path = Path(project_root) / db_path
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä¼æ¥­åˆ†é¡å®šç¾©
        self.market_categories = {
            'high_share': ['ãƒ­ãƒœãƒƒãƒˆ', 'å†…è¦–é¡', 'å·¥ä½œæ©Ÿæ¢°', 'é›»å­ææ–™', 'ç²¾å¯†æ¸¬å®šæ©Ÿå™¨'],
            'declining': ['è‡ªå‹•è»Š', 'é‰„é‹¼', 'ã‚¹ãƒãƒ¼ãƒˆå®¶é›»', 'ãƒãƒƒãƒ†ãƒªãƒ¼', 'PCãƒ»å‘¨è¾ºæ©Ÿå™¨'],
            'lost_share': ['å®¶é›»', 'åŠå°ä½“', 'ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³', 'PC', 'é€šä¿¡æ©Ÿå™¨']
        }
        
        self.logger.info(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹: {self.db_path}")
    
    def create_database(self) -> bool:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆãƒ»åˆæœŸåŒ–
        
        Returns:
            bool: æˆåŠŸæ™‚True
        """
        try:
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            if self.db_path.exists():
                backup_path = self.db_path.with_suffix(
                    f'.backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.db'
                )
                self.db_path.rename(backup_path)
                self.logger.info(f"æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_path}")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ»ä½œæˆ
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("PRAGMA foreign_keys = ON")
                cursor = conn.cursor()
                
                # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
                self._create_master_tables(cursor)
                self._create_financial_tables(cursor)
                self._create_lifecycle_tables(cursor)
                self._create_market_tables(cursor)
                self._create_analysis_tables(cursor)
                
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
                self._create_indexes(cursor)
                
                # åˆæœŸãƒ‡ãƒ¼ã‚¿æŠ•å…¥
                self._insert_initial_data(cursor)
                
                conn.commit()
                self.logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆå®Œäº†")
                return True
                
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _create_master_tables(self, cursor: sqlite3.Cursor) -> None:
        """ãƒã‚¹ã‚¿ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        
        # ä¼æ¥­ãƒã‚¹ã‚¿ãƒ¼
        cursor.execute("""
        CREATE TABLE companies (
            company_id INTEGER PRIMARY KEY AUTOINCREMENT,
            company_name TEXT NOT NULL UNIQUE,
            company_code TEXT UNIQUE,  -- è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰
            market_category TEXT NOT NULL CHECK (market_category IN ('high_share', 'declining', 'lost_share')),
            market_sector TEXT NOT NULL,  -- å…·ä½“çš„ãªå¸‚å ´ï¼ˆãƒ­ãƒœãƒƒãƒˆã€å†…è¦–é¡ç­‰ï¼‰
            founded_date DATE,
            listed_date DATE,
            delisted_date DATE,
            extinction_date DATE,
            current_status TEXT NOT NULL DEFAULT 'active' CHECK (current_status IN ('active', 'delisted', 'merged', 'bankrupt', 'spinoff')),
            parent_company_id INTEGER,
            data_start_year INTEGER NOT NULL,
            data_end_year INTEGER,
            notes TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (parent_company_id) REFERENCES companies (company_id)
        )
        """)
        
        # å¸‚å ´ã‚»ã‚¯ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼
        cursor.execute("""
        CREATE TABLE market_sectors (
            sector_id INTEGER PRIMARY KEY AUTOINCREMENT,
            sector_name TEXT NOT NULL UNIQUE,
            category TEXT NOT NULL CHECK (category IN ('high_share', 'declining', 'lost_share')),
            description TEXT,
            global_market_size_usd REAL,
            japan_share_percentage REAL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """)
        
        # è©•ä¾¡é …ç›®ãƒã‚¹ã‚¿ãƒ¼
        cursor.execute("""
        CREATE TABLE evaluation_metrics (
            metric_id INTEGER PRIMARY KEY AUTOINCREMENT,
            metric_name TEXT NOT NULL UNIQUE,
            metric_code TEXT NOT NULL UNIQUE,
            description TEXT,
            unit TEXT,
            calculation_method TEXT,
            is_traditional BOOLEAN DEFAULT TRUE,  -- å¾“æ¥6é …ç›® or æ–°è¦3é …ç›®
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        """)
        
        # è¦å› é …ç›®ãƒã‚¹ã‚¿ãƒ¼
        cursor.execute("""
        CREATE TABLE factor_metrics (
            factor_id INTEGER PRIMARY KEY AUTOINCREMENT,
            evaluation_metric_id INTEGER NOT NULL,
            factor_name TEXT NOT NULL,
            factor_code TEXT NOT NULL,
            factor_category TEXT NOT NULL,  -- æŠ•è³‡ãƒ»è³‡ç”£é–¢é€£ã€äººçš„è³‡æºé–¢é€£ç­‰
            description TEXT,
            unit TEXT,
            calculation_method TEXT,
            data_source TEXT,  -- è²¸å€Ÿå¯¾ç…§è¡¨ã€æç›Šè¨ˆç®—æ›¸ã€CFç­‰
            is_extended BOOLEAN DEFAULT FALSE,  -- æ‹¡å¼µé …ç›®ï¼ˆä¼æ¥­å¹´é½¢ç­‰ï¼‰
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (evaluation_metric_id) REFERENCES evaluation_metrics (metric_id),
            UNIQUE(evaluation_metric_id, factor_code)
        )
        """)
        
        self.logger.info("ãƒã‚¹ã‚¿ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆå®Œäº†")
    
    def _create_financial_tables(self, cursor: sqlite3.Cursor) -> None:
        """è²¡å‹™ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        
        # è²¡å‹™è«¸è¡¨ãƒ¡ã‚¤ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
        CREATE TABLE financial_statements (
            statement_id INTEGER PRIMARY KEY AUTOINCREMENT,
            company_id INTEGER NOT NULL,
            fiscal_year INTEGER NOT NULL,
            fiscal_end_date DATE,
            statement_type TEXT NOT NULL CHECK (statement_type IN ('annual', 'quarterly')),
            accounting_standard TEXT DEFAULT 'JGAAP' CHECK (accounting_standard IN ('JGAAP', 'IFRS', 'USGAAP')),
            currency TEXT DEFAULT 'JPY',
            
            -- åŸºæœ¬è²¡å‹™æŒ‡æ¨™
            revenue REAL,                    -- å£²ä¸Šé«˜
            gross_profit REAL,               -- å£²ä¸Šç·åˆ©ç›Š
            operating_profit REAL,           -- å–¶æ¥­åˆ©ç›Š
            ordinary_profit REAL,            -- çµŒå¸¸åˆ©ç›Š
            net_income REAL,                 -- å½“æœŸç´”åˆ©ç›Š
            total_assets REAL,               -- ç·è³‡ç”£
            shareholders_equity REAL,        -- æ ªä¸»è³‡æœ¬
            total_liabilities REAL,          -- ç·è² å‚µ
            
            -- å¾“æ¥­å“¡ãƒ»äººçš„ãƒ‡ãƒ¼ã‚¿
            employee_count INTEGER,          -- å¾“æ¥­å“¡æ•°
            average_annual_salary REAL,      -- å¹³å‡å¹´é–“çµ¦ä¸
            
            -- ãƒ‡ãƒ¼ã‚¿å“è³ªæƒ…å ±
            data_quality_score REAL DEFAULT 1.0,  -- 1.0=å®Œå…¨, 0.0=æ¨å®šå€¤
            is_estimated BOOLEAN DEFAULT FALSE,
            estimation_method TEXT,
            
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (company_id) REFERENCES companies (company_id),
            UNIQUE(company_id, fiscal_year, statement_type)
        )
        """)
        
        # è©•ä¾¡é …ç›®ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
        CREATE TABLE evaluation_data (
            eval_data_id INTEGER PRIMARY KEY AUTOINCREMENT,
            company_id INTEGER NOT NULL,
            fiscal_year INTEGER NOT NULL,
            metric_id INTEGER NOT NULL,
            value REAL,
            calculated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            calculation_version TEXT DEFAULT '1.0',
            is_estimated BOOLEAN DEFAULT FALSE,
            FOREIGN KEY (company_id) REFERENCES companies (company_id),
            FOREIGN KEY (metric_id) REFERENCES evaluation_metrics (metric_id),
            UNIQUE(company_id, fiscal_year, metric_id)
        )
        """)
        
        # è¦å› é …ç›®ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
        CREATE TABLE factor_data (
            factor_data_id INTEGER PRIMARY KEY AUTOINCREMENT,
            company_id INTEGER NOT NULL,
            fiscal_year INTEGER NOT NULL,
            factor_id INTEGER NOT NULL,
            value REAL,
            calculated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            calculation_version TEXT DEFAULT '1.0',
            is_estimated BOOLEAN DEFAULT FALSE,
            estimation_confidence REAL DEFAULT 1.0,  -- æ¨å®šä¿¡é ¼åº¦
            FOREIGN KEY (company_id) REFERENCES companies (company_id),
            FOREIGN KEY (factor_id) REFERENCES factor_metrics (factor_id),
            UNIQUE(company_id, fiscal_year, factor_id)
        )
        """)
        
        self.logger.info("è²¡å‹™ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆå®Œäº†")
    
    def _create_lifecycle_tables(self, cursor: sqlite3.Cursor) -> None:
        """ä¼æ¥­ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«é–¢é€£ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        
        # ä¼æ¥­ã‚¤ãƒ™ãƒ³ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
        CREATE TABLE corporate_events (
            event_id INTEGER PRIMARY KEY AUTOINCREMENT,
            company_id INTEGER NOT NULL,
            event_type TEXT NOT NULL CHECK (event_type IN (
                'founding', 'listing', 'delisting', 'merger', 'acquisition', 
                'spinoff', 'bankruptcy', 'restructure', 'name_change'
            )),
            event_date DATE NOT NULL,
            description TEXT,
            related_company_id INTEGER,  -- ç›¸æ‰‹ä¼æ¥­ï¼ˆM&Aç­‰ï¼‰
            financial_impact REAL,       -- è²¡å‹™çš„å½±éŸ¿é¡
            market_impact_description TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (company_id) REFERENCES companies (company_id),
            FOREIGN KEY (related_company_id) REFERENCES companies (company_id)
        )
        """)
        
        # ç”Ÿå­˜åˆ†æãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
        CREATE TABLE survival_data (
            survival_id INTEGER PRIMARY KEY AUTOINCREMENT,
            company_id INTEGER NOT NULL,
            observation_start_year INTEGER NOT NULL,
            observation_end_year INTEGER,
            survival_time_years INTEGER,  -- è¦³æ¸¬æœŸé–“ï¼ˆå¹´ï¼‰
            event_occurred BOOLEAN DEFAULT FALSE,  -- ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿï¼ˆæ¶ˆæ»…=TRUEï¼‰
            event_type TEXT,  -- æ¶ˆæ»…ç†ç”±
            censored BOOLEAN DEFAULT FALSE,  -- æ‰“ã¡åˆ‡ã‚Šãƒ‡ãƒ¼ã‚¿
            market_category TEXT NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (company_id) REFERENCES companies (company_id),
            UNIQUE(company_id)
        )
        """)
        
        # ä¼æ¥­ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
        CREATE TABLE lifecycle_stages (
            stage_id INTEGER PRIMARY KEY AUTOINCREMENT,
            company_id INTEGER NOT NULL,
            fiscal_year INTEGER NOT NULL,
            stage TEXT NOT NULL CHECK (stage IN (
                'startup', 'growth', 'maturity', 'decline', 'turnaround', 'exit'
            )),
            stage_score REAL,  -- ã‚¹ãƒ†ãƒ¼ã‚¸ã‚¹ã‚³ã‚¢ï¼ˆ0-1ï¼‰
            transition_probability REAL,  -- æ¬¡ã‚¹ãƒ†ãƒ¼ã‚¸ç§»è¡Œç¢ºç‡
            calculated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (company_id) REFERENCES companies (company_id),
            UNIQUE(company_id, fiscal_year)
        )
        """)
        
        self.logger.info("ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆå®Œäº†")
    
    def _create_market_tables(self, cursor: sqlite3.Cursor) -> None:
        """å¸‚å ´ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        
        # ä¸–ç•Œå¸‚å ´ã‚·ã‚§ã‚¢ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
        CREATE TABLE market_share_data (
            share_id INTEGER PRIMARY KEY AUTOINCREMENT,
            company_id INTEGER NOT NULL,
            fiscal_year INTEGER NOT NULL,
            market_sector TEXT NOT NULL,
            global_share_percentage REAL,
            regional_share_percentage REAL,
            market_size_usd REAL,
            market_rank INTEGER,
            data_source TEXT,
            reliability_score REAL DEFAULT 1.0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (company_id) REFERENCES companies (company_id)
        )
        """)
        
        # æ¥­ç•Œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿
        cursor.execute("""
        CREATE TABLE industry_benchmarks (
            benchmark_id INTEGER PRIMARY KEY AUTOINCREMENT,
            market_sector TEXT NOT NULL,
            fiscal_year INTEGER NOT NULL,
            metric_name TEXT NOT NULL,
            benchmark_value REAL,
            benchmark_type TEXT CHECK (benchmark_type IN ('median', 'average', 'top_quartile', 'bottom_quartile')),
            sample_size INTEGER,
            data_source TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(market_sector, fiscal_year, metric_name, benchmark_type)
        )
        """)
        
        self.logger.info("å¸‚å ´ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆå®Œäº†")
    
    def _create_analysis_tables(self, cursor: sqlite3.Cursor) -> None:
        """åˆ†æçµæœãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        
        # åˆ†æå®Ÿè¡Œå±¥æ­´
        cursor.execute("""
        CREATE TABLE analysis_runs (
            run_id INTEGER PRIMARY KEY AUTOINCREMENT,
            analysis_type TEXT NOT NULL CHECK (analysis_type IN (
                'factor_impact', 'market_comparison', 'survival_analysis', 
                'emergence_analysis', 'causal_inference', 'integrated_analysis'
            )),
            run_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            parameters TEXT,  -- JSONå½¢å¼ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            sample_size INTEGER,
            model_version TEXT,
            status TEXT DEFAULT 'running' CHECK (status IN ('running', 'completed', 'failed')),
            results_path TEXT,
            created_by TEXT DEFAULT 'system'
        )
        """)
        
        # å› æœæ¨è«–çµæœ
        cursor.execute("""
        CREATE TABLE causal_effects (
            effect_id INTEGER PRIMARY KEY AUTOINCREMENT,
            run_id INTEGER NOT NULL,
            treatment_factor_id INTEGER NOT NULL,
            outcome_metric_id INTEGER NOT NULL,
            causal_effect REAL,
            confidence_interval_lower REAL,
            confidence_interval_upper REAL,
            p_value REAL,
            method TEXT NOT NULL,  -- 'did', 'iv', 'psm', 'causal_forest'
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (run_id) REFERENCES analysis_runs (run_id),
            FOREIGN KEY (treatment_factor_id) REFERENCES factor_metrics (factor_id),
            FOREIGN KEY (outcome_metric_id) REFERENCES evaluation_metrics (metric_id)
        )
        """)
        
        # äºˆæ¸¬çµæœãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
        CREATE TABLE predictions (
            prediction_id INTEGER PRIMARY KEY AUTOINCREMENT,
            company_id INTEGER NOT NULL,
            prediction_type TEXT NOT NULL CHECK (prediction_type IN (
                'survival_probability', 'performance_forecast', 'market_share_forecast'
            )),
            target_year INTEGER NOT NULL,
            predicted_value REAL,
            confidence_interval_lower REAL,
            confidence_interval_upper REAL,
            model_name TEXT,
            prediction_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (company_id) REFERENCES companies (company_id)
        )
        """)
        
        self.logger.info("åˆ†æãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆå®Œäº†")
    
    def _create_indexes(self, cursor: sqlite3.Cursor) -> None:
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
        
        indexes = [
            # ä¼æ¥­é–¢é€£ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            "CREATE INDEX idx_companies_market_category ON companies(market_category)",
            "CREATE INDEX idx_companies_status ON companies(current_status)",
            "CREATE INDEX idx_companies_sector ON companies(market_sector)",
            
            # è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            "CREATE INDEX idx_financial_year ON financial_statements(company_id, fiscal_year)",
            "CREATE INDEX idx_evaluation_data_year ON evaluation_data(company_id, fiscal_year)",
            "CREATE INDEX idx_factor_data_year ON factor_data(company_id, fiscal_year)",
            
            # ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«é–¢é€£ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            "CREATE INDEX idx_events_company_date ON corporate_events(company_id, event_date)",
            "CREATE INDEX idx_survival_category ON survival_data(market_category)",
            "CREATE INDEX idx_lifecycle_stages_year ON lifecycle_stages(company_id, fiscal_year)",
            
            # å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            "CREATE INDEX idx_market_share_year ON market_share_data(company_id, fiscal_year)",
            "CREATE INDEX idx_benchmarks_sector_year ON industry_benchmarks(market_sector, fiscal_year)",
            
            # åˆ†æçµæœã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            "CREATE INDEX idx_analysis_runs_type ON analysis_runs(analysis_type, run_timestamp)",
            "CREATE INDEX idx_causal_effects_factors ON causal_effects(treatment_factor_id, outcome_metric_id)",
            "CREATE INDEX idx_predictions_company_type ON predictions(company_id, prediction_type)"
        ]
        
        for index_sql in indexes:
            cursor.execute(index_sql)
        
        self.logger.info("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†")
    
    def _insert_initial_data(self, cursor: sqlite3.Cursor) -> None:
        """åˆæœŸãƒ‡ãƒ¼ã‚¿æŠ•å…¥"""
        
        # å¸‚å ´ã‚»ã‚¯ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼æŠ•å…¥
        sectors_data = []
        for category, sectors in self.market_categories.items():
            for sector in sectors:
                sectors_data.append((sector, category, f"{category}å¸‚å ´ã®{sector}åˆ†é‡"))
        
        cursor.executemany("""
        INSERT INTO market_sectors (sector_name, category, description)
        VALUES (?, ?, ?)
        """, sectors_data)
        
        # è©•ä¾¡é …ç›®ãƒã‚¹ã‚¿ãƒ¼æŠ•å…¥
        evaluation_metrics = [
            ('å£²ä¸Šé«˜', 'revenue', 'ä¼æ¥­ã®å£²ä¸Šé«˜', 'ç™¾ä¸‡å††', 'financial_statements.revenue', True),
            ('å£²ä¸Šé«˜æˆé•·ç‡', 'revenue_growth', 'å£²ä¸Šé«˜ã®å‰å¹´åŒæœŸæ¯”æˆé•·ç‡', '%', '(revenue_t - revenue_t-1) / revenue_t-1 * 100', True),
            ('å£²ä¸Šé«˜å–¶æ¥­åˆ©ç›Šç‡', 'operating_margin', 'å£²ä¸Šé«˜ã«å¯¾ã™ã‚‹å–¶æ¥­åˆ©ç›Šã®æ¯”ç‡', '%', 'operating_profit / revenue * 100', True),
            ('å£²ä¸Šé«˜å½“æœŸç´”åˆ©ç›Šç‡', 'net_margin', 'å£²ä¸Šé«˜ã«å¯¾ã™ã‚‹å½“æœŸç´”åˆ©ç›Šã®æ¯”ç‡', '%', 'net_income / revenue * 100', True),
            ('ROE', 'roe', 'è‡ªå·±è³‡æœ¬åˆ©ç›Šç‡', '%', 'net_income / shareholders_equity * 100', True),
            ('å£²ä¸Šé«˜ä»˜åŠ ä¾¡å€¤ç‡', 'value_added_ratio', 'å£²ä¸Šé«˜ä»˜åŠ ä¾¡å€¤ç‡', '%', 'ä»˜åŠ ä¾¡å€¤ / å£²ä¸Šé«˜ * 100', True),
            ('ä¼æ¥­å­˜ç¶šç¢ºç‡', 'survival_probability', 'ç”Ÿå­˜åˆ†æã«ã‚ˆã‚‹ä¼æ¥­å­˜ç¶šç¢ºç‡', 'ç¢ºç‡', 'survival_model_prediction', False),
            ('æ–°è¦äº‹æ¥­æˆåŠŸç‡', 'emergence_success_rate', 'æ–°è¨­ä¼æ¥­ãƒ»æ–°è¦äº‹æ¥­ã®æˆåŠŸç‡', '%', 'emergence_model_prediction', False),
            ('äº‹æ¥­ç¶™æ‰¿æˆåŠŸåº¦', 'succession_success', 'M&Aãƒ»åˆ†ç¤¾åŒ–ã®æˆåŠŸåº¦', 'ã‚¹ã‚³ã‚¢', 'succession_model_prediction', False)
        ]
        
        cursor.executemany("""
        INSERT INTO evaluation_metrics (metric_name, metric_code, description, unit, calculation_method, is_traditional)
        VALUES (?, ?, ?, ?, ?, ?)
        """, evaluation_metrics)
        
        # è¦å› é …ç›®ãƒã‚¹ã‚¿ãƒ¼ã®ä¸€éƒ¨æŠ•å…¥ï¼ˆå£²ä¸Šé«˜é–¢é€£ã®ã¿ä¾‹ç¤ºï¼‰
        cursor.execute("SELECT metric_id FROM evaluation_metrics WHERE metric_code = 'revenue'")
        revenue_metric_id = cursor.fetchone()[0]
        
        revenue_factors = [
            (revenue_metric_id, 'æœ‰å½¢å›ºå®šè³‡ç”£', 'tangible_assets', 'æŠ•è³‡ãƒ»è³‡ç”£é–¢é€£', 'æœ‰å½¢å›ºå®šè³‡ç”£æ®‹é«˜', 'ç™¾ä¸‡å††', 'balance_sheet.tangible_assets', 'è²¸å€Ÿå¯¾ç…§è¡¨'),
            (revenue_metric_id, 'è¨­å‚™æŠ•è³‡é¡', 'capex', 'æŠ•è³‡ãƒ»è³‡ç”£é–¢é€£', 'è¨­å‚™æŠ•è³‡é¡', 'ç™¾ä¸‡å††', 'cash_flow.capex', 'ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼è¨ˆç®—æ›¸'),
            (revenue_metric_id, 'ç ”ç©¶é–‹ç™ºè²»', 'rd_expenses', 'æŠ•è³‡ãƒ»è³‡ç”£é–¢é€£', 'ç ”ç©¶é–‹ç™ºè²»', 'ç™¾ä¸‡å††', 'income_statement.rd_expenses', 'æç›Šè¨ˆç®—æ›¸'),
            (revenue_metric_id, 'å¾“æ¥­å“¡æ•°', 'employee_count', 'äººçš„è³‡æºé–¢é€£', 'å¾“æ¥­å“¡æ•°', 'äºº', 'notes.employee_count', 'æ³¨è¨˜æƒ…å ±'),
            (revenue_metric_id, 'ä¼æ¥­å¹´é½¢', 'company_age', 'ä¼æ¥­ç‰¹æ€§', 'è¨­ç«‹ã‹ã‚‰ã®çµŒéå¹´æ•°', 'å¹´', 'fiscal_year - founded_year', 'è¨ˆç®—å€¤', True)
        ]
        
        cursor.executemany("""
        INSERT INTO factor_metrics (evaluation_metric_id, factor_name, factor_code, factor_category, 
                                    description, unit, calculation_method, data_source, is_extended)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, revenue_factors)
        
        self.logger.info("åˆæœŸãƒ‡ãƒ¼ã‚¿æŠ•å…¥å®Œäº†")
    
    def insert_company_data(self, companies_csv_path: Optional[str] = None) -> bool:
        """
        ä¼æ¥­ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
        
        Args:
            companies_csv_path: ä¼æ¥­ãƒªã‚¹ãƒˆCSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            bool: æˆåŠŸæ™‚True
        """
        try:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ä¼æ¥­ãƒªã‚¹ãƒˆï¼ˆæ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰
            if companies_csv_path is None:
                companies_data = self._get_default_companies_data()
            else:
                companies_data = pd.read_csv(companies_csv_path)
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                for _, row in companies_data.iterrows():
                    cursor.execute("""
                    INSERT OR REPLACE INTO companies (
                        company_name, market_category, market_sector, 
                        data_start_year, data_end_year, current_status
                    ) VALUES (?, ?, ?, ?, ?, ?)
                    """, (
                        row['company_name'],
                        row['market_category'],
                        row['market_sector'],
                        row.get('data_start_year', 1984),
                        row.get('data_end_year', 2024),
                        row.get('current_status', 'active')
                    ))
                
                conn.commit()
                self.logger.info(f"ä¼æ¥­ãƒ‡ãƒ¼ã‚¿æŠ•å…¥å®Œäº†: {len(companies_data)}ç¤¾")
                return True
                
        except Exception as e:
            self.logger.error(f"ä¼æ¥­ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _get_default_companies_data(self) -> pd.DataFrame:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¼æ¥­ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        
        # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®ä¼æ¥­ãƒªã‚¹ãƒˆï¼ˆä¸€éƒ¨æŠœç²‹ï¼‰
        companies_list = [
            # é«˜ã‚·ã‚§ã‚¢å¸‚å ´ - ãƒ­ãƒœãƒƒãƒˆ
            {'company_name': 'ãƒ•ã‚¡ãƒŠãƒƒã‚¯', 'market_category': 'high_share', 'market_sector': 'ãƒ­ãƒœãƒƒãƒˆ'},
            {'company_name': 'å®‰å·é›»æ©Ÿ', 'market_category': 'high_share', 'market_sector': 'ãƒ­ãƒœãƒƒãƒˆ'},
            {'company_name': 'å·å´é‡å·¥æ¥­', 'market_category': 'high_share', 'market_sector': 'ãƒ­ãƒœãƒƒãƒˆ'},
            
            # é«˜ã‚·ã‚§ã‚¢å¸‚å ´ - å†…è¦–é¡
            {'company_name': 'ã‚ªãƒªãƒ³ãƒ‘ã‚¹', 'market_category': 'high_share', 'market_sector': 'å†…è¦–é¡'},
            {'company_name': 'HOYA', 'market_category': 'high_share', 'market_sector': 'å†…è¦–é¡'},
            {'company_name': 'å¯Œå£«ãƒ•ã‚¤ãƒ«ãƒ ', 'market_category': 'high_share', 'market_sector': 'å†…è¦–é¡'},
            
            # ã‚·ã‚§ã‚¢ä½ä¸‹å¸‚å ´ - è‡ªå‹•è»Š
            {'company_name': 'ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Š', 'market_category': 'declining', 'market_sector': 'è‡ªå‹•è»Š'},
            {'company_name': 'æ—¥ç”£è‡ªå‹•è»Š', 'market_category': 'declining', 'market_sector': 'è‡ªå‹•è»Š'},
            {'company_name': 'ãƒ›ãƒ³ãƒ€', 'market_category': 'declining', 'market_sector': 'è‡ªå‹•è»Š'},
            
            # å®Œå…¨å¤±å¤±å¸‚å ´ - åŠå°ä½“
            {'company_name': 'ã‚½ãƒ‹ãƒ¼', 'market_category': 'lost_share', 'market_sector': 'åŠå°ä½“', 'current_status': 'active'},
            {'company_name': 'ä¸‰æ´‹é›»æ©Ÿ', 'market_category': 'lost_share', 'market_sector': 'å®¶é›»', 'current_status': 'merged', 'data_end_year': 2012},
        ]
        
        return pd.DataFrame(companies_list)
    
    def validate_database(self) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹é€ æ¤œè¨¼"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # ãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ç¢ºèª
                cursor.execute("""
                SELECT name FROM sqlite_master WHERE type='table' ORDER BY name
                """)
                tables = [row[0] for row in cursor.fetchall()]
                
                expected_tables = [
                    'companies', 'market_sectors', 'evaluation_metrics', 'factor_metrics',
                    'financial_statements', 'evaluation_data', 'factor_data',
                    'corporate_events', 'survival_data', 'lifecycle_stages',
                    'market_share_data', 'industry_benchmarks',
                    'analysis_runs', 'causal_effects', 'predictions'
                ]
                
                missing_tables = set(expected_tables) - set(tables)
                if missing_tables:
                    self.logger.error(f"ä¸è¶³ãƒ†ãƒ¼ãƒ–ãƒ«: {missing_tables}")
                    return False
                
                # ãƒ‡ãƒ¼ã‚¿å­˜åœ¨ç¢ºèª
                cursor.execute("SELECT COUNT(*) FROM companies")
                company_count = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) FROM evaluation_metrics")
                metrics_count = cursor.fetchone()[0]
                
                self.logger.info(f"æ¤œè¨¼çµæœ - ä¼æ¥­æ•°: {company_count}, è©•ä¾¡é …ç›®æ•°: {metrics_count}")
                return True
                
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def get_database_info(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±å–å¾—"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                info = {
                    'database_path': str(self.db_path),
                    'database_size_mb': self.db_path.stat().st_size / (1024 * 1024),
                    'created_at': datetime.fromtimestamp(self.db_path.stat().st_ctime).isoformat(),
                }
                
                # ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                tables = [row[0] for row in cursor.fetchall()]
                
                for table in tables:
                    cursor.execute(f"SELECT COUNT(*) FROM {table}")
                    count = cursor.fetchone()[0]
                    info[f'{table}_count'] = count
                
                return info
                
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import argparse
    
    parser = argparse.ArgumentParser(description='A2AI Database Setup')
    parser.add_argument('--db-path', help='Database file path')
    parser.add_argument('--companies-csv', help='Companies CSV file path')
    parser.add_argument('--reset', action='store_true', help='Reset existing database')
    parser.add_argument('--validate-only', action='store_true', help='Validate database only')
    parser.add_argument('--info', action='store_true', help='Show database info')
    args = parser.parse_args()
    
    # ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('logs/database_setup.log'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    db_setup = A2AIDatabaseSetup(args.db_path)
    
    try:
        if args.info:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±è¡¨ç¤º
            info = db_setup.get_database_info()
            print("\n=== A2AI Database Information ===")
            for key, value in info.items():
                print(f"{key}: {value}")
            return
        
        if args.validate_only:
            # æ¤œè¨¼ã®ã¿å®Ÿè¡Œ
            if db_setup.validate_database():
                print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼æˆåŠŸ")
                return
            else:
                print("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼å¤±æ•—")
                sys.exit(1)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ
        print("ğŸš€ A2AI ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹...")
        
        if not db_setup.create_database():
            print("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆå¤±æ•—")
            sys.exit(1)
        
        # ä¼æ¥­ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
        print("ğŸ“Š ä¼æ¥­ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ä¸­...")
        if not db_setup.insert_company_data(args.companies_csv):
            print("âš ï¸ ä¼æ¥­ãƒ‡ãƒ¼ã‚¿æŠ•å…¥å¤±æ•—")
        
        # æ¤œè¨¼å®Ÿè¡Œ
        print("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼ä¸­...")
        if not db_setup.validate_database():
            print("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼å¤±æ•—")
            sys.exit(1)
        
        # æƒ…å ±è¡¨ç¤º
        info = db_setup.get_database_info()
        print("\nâœ… A2AI ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†!")
        print(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹: {info['database_path']}")
        print(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚º: {info['database_size_mb']:.2f} MB")
        print(f"ğŸ¢ ç™»éŒ²ä¼æ¥­æ•°: {info.get('companies_count', 0)}")
        print(f"ğŸ“ˆ è©•ä¾¡é …ç›®æ•°: {info.get('evaluation_metrics_count', 0)}")
        print(f"âš™ï¸ è¦å› é …ç›®æ•°: {info.get('factor_metrics_count', 0)}")
        
        print("\nğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. collect_all_data.py ã§ãƒ‡ãƒ¼ã‚¿åé›†ã‚’é–‹å§‹")
        print("2. preprocess_pipeline.py ã§å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ")
        print("3. train_survival_models.py ã§ç”Ÿå­˜åˆ†æãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        logging.exception("Setup failed")
        sys.exit(1)


class A2AICompanyDataGenerator:
    """ä¼æ¥­ãƒ‡ãƒ¼ã‚¿è‡ªå‹•ç”Ÿæˆã‚¯ãƒ©ã‚¹ï¼ˆ150ç¤¾å®Œå…¨ç‰ˆï¼‰"""
    
    def __init__(self):
        self.logger = setup_logger(__name__, LOGGING_CONFIG)
    
    def generate_complete_company_list(self) -> pd.DataFrame:
        """
        æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®å®Œå…¨ãª150ç¤¾ä¼æ¥­ãƒªã‚¹ãƒˆç”Ÿæˆ
        
        Returns:
            pd.DataFrame: 150ç¤¾ã®å®Œå…¨ä¼æ¥­ãƒ‡ãƒ¼ã‚¿
        """
        companies = []
        
        # é«˜ã‚·ã‚§ã‚¢å¸‚å ´ (50ç¤¾)
        high_share_companies = {
            'ãƒ­ãƒœãƒƒãƒˆ': [
                'ãƒ•ã‚¡ãƒŠãƒƒã‚¯', 'å®‰å·é›»æ©Ÿ', 'å·å´é‡å·¥æ¥­', 'ä¸äºŒè¶Š', 'ãƒ‡ãƒ³ã‚½ãƒ¼ã‚¦ã‚§ãƒ¼ãƒ–',
                'ä¸‰è±é›»æ©Ÿ', 'ã‚ªãƒ ãƒ­ãƒ³', 'THK', 'NSK', 'IHI'
            ],
            'å†…è¦–é¡': [
                'ã‚ªãƒªãƒ³ãƒ‘ã‚¹', 'HOYA', 'å¯Œå£«ãƒ•ã‚¤ãƒ«ãƒ ', 'ã‚­ãƒ¤ãƒãƒ³ãƒ¡ãƒ‡ã‚£ã‚«ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚º',
                'å³¶æ´¥è£½ä½œæ‰€', 'ã‚³ãƒ‹ã‚«ãƒŸãƒãƒ«ã‚¿', 'ã‚½ãƒ‹ãƒ¼', 'ãƒˆãƒ—ã‚³ãƒ³', 'ã‚¨ãƒ ã‚¹ãƒªãƒ¼', 'æ—¥ç«‹è£½ä½œæ‰€'
            ],
            'å·¥ä½œæ©Ÿæ¢°': [
                'DMGæ£®ç²¾æ©Ÿ', 'ãƒ¤ãƒã‚¶ã‚­ãƒã‚¶ãƒƒã‚¯', 'ã‚ªãƒ¼ã‚¯ãƒ', 'ç‰§é‡ãƒ•ãƒ©ã‚¤ã‚¹è£½ä½œæ‰€',
                'ã‚¸ã‚§ã‚¤ãƒ†ã‚¯ãƒˆ', 'æ±èŠæ©Ÿæ¢°', 'ã‚¢ãƒãƒ€', 'ã‚½ãƒ‡ã‚£ãƒƒã‚¯', 'ä¸‰è±é‡å·¥å·¥ä½œæ©Ÿæ¢°', 'ã‚·ã‚®ãƒ¤ç²¾æ©Ÿè£½ä½œæ‰€'
            ],
            'é›»å­ææ–™': [
                'æ‘ç”°è£½ä½œæ‰€', 'TDK', 'äº¬ã‚»ãƒ©', 'å¤ªé™½èª˜é›»', 'æ—¥æœ¬ç‰¹æ®Šé™¶æ¥­',
                'ãƒ­ãƒ¼ãƒ ', 'ãƒ—ãƒ­ãƒ†ãƒªã‚¢ãƒ«', 'ä½å‹é›»å·¥', 'æ—¥æ±é›»å·¥', 'æ—¥æœ¬ç¢å­'
            ],
            'ç²¾å¯†æ¸¬å®šæ©Ÿå™¨': [
                'ã‚­ãƒ¼ã‚¨ãƒ³ã‚¹', 'å³¶æ´¥è£½ä½œæ‰€', 'å €å ´è£½ä½œæ‰€', 'æ±äº¬ç²¾å¯†', 'ãƒŸãƒ„ãƒˆãƒ¨',
                'ã‚ªãƒªãƒ³ãƒ‘ã‚¹', 'æ—¥æœ¬é›»ç”£', 'ãƒªã‚ªãƒ³', 'ã‚¢ãƒ«ãƒãƒƒã‚¯', 'ãƒŠãƒ–ãƒ†ã‚¹ã‚³'
            ]
        }
        
        # ã‚·ã‚§ã‚¢ä½ä¸‹å¸‚å ´ (50ç¤¾)
        declining_companies = {
            'è‡ªå‹•è»Š': [
                'ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Š', 'æ—¥ç”£è‡ªå‹•è»Š', 'ãƒ›ãƒ³ãƒ€', 'ã‚¹ã‚ºã‚­', 'ãƒãƒ„ãƒ€',
                'SUBARU', 'ã„ã™ã‚è‡ªå‹•è»Š', 'ä¸‰è±è‡ªå‹•è»Š', 'ãƒ€ã‚¤ãƒãƒ„å·¥æ¥­', 'æ—¥é‡è‡ªå‹•è»Š'
            ],
            'é‰„é‹¼': [
                'æ—¥æœ¬è£½é‰„', 'JFEãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹', 'ç¥æˆ¸è£½é‹¼æ‰€', 'æ—¥æ–°è£½é‹¼', 'å¤§åŒç‰¹æ®Šé‹¼',
                'å±±é™½ç‰¹æ®Šè£½é‹¼', 'æ„›çŸ¥è£½é‹¼', 'ä¸­éƒ¨é‹¼éˆ‘', 'æ·€å·è£½é‹¼æ‰€', 'æ—¥ç«‹é‡‘å±'
            ],
            'ã‚¹ãƒãƒ¼ãƒˆå®¶é›»': [
                'ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯', 'ã‚·ãƒ£ãƒ¼ãƒ—', 'ã‚½ãƒ‹ãƒ¼', 'æ±èŠãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«',
                'æ—¥ç«‹ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ©ã‚¤ãƒ•ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚º', 'ã‚¢ã‚¤ãƒªã‚¹ã‚ªãƒ¼ãƒ¤ãƒ', 'ä¸‰è±é›»æ©Ÿ',
                'è±¡å°ãƒãƒ›ãƒ¼ãƒ“ãƒ³', 'ã‚¿ã‚¤ã‚¬ãƒ¼é­”æ³•ç“¶', 'å±±å–„'
            ],
            'ãƒãƒƒãƒ†ãƒªãƒ¼': [
                'ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯ã‚¨ãƒŠã‚¸ãƒ¼', 'æ‘ç”°è£½ä½œæ‰€', 'GSãƒ¦ã‚¢ã‚µ', 'æ±èŠã‚¤ãƒ³ãƒ•ãƒ©ã‚·ã‚¹ãƒ†ãƒ ã‚º',
                'æ—¥ç«‹åŒ–æˆ', 'FDK', 'NEC', 'ENAX', 'æ—¥æœ¬é›»ç”£', 'TDK'
            ],
            'PCãƒ»å‘¨è¾ºæ©Ÿå™¨': [
                'NECãƒ‘ãƒ¼ã‚½ãƒŠãƒ«', 'å¯Œå£«é€šã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°', 'æ±èŠãƒ€ã‚¤ãƒŠãƒ–ãƒƒã‚¯',
                'ã‚½ãƒ‹ãƒ¼VAIO', 'ã‚¨ãƒ¬ã‚³ãƒ ', 'ãƒãƒƒãƒ•ã‚¡ãƒ­ãƒ¼', 'ãƒ­ã‚¸ãƒ†ãƒƒã‚¯', 'ãƒ—ãƒªãƒ³ã‚¹ãƒˆãƒ³',
                'ã‚µãƒ³ãƒ¯ã‚µãƒ—ãƒ©ã‚¤', 'ã‚¢ã‚¤ãƒ»ã‚ªãƒ¼ãƒ»ãƒ‡ãƒ¼ã‚¿æ©Ÿå™¨'
            ]
        }
        
        # å®Œå…¨å¤±å¤±å¸‚å ´ (50ç¤¾)
        lost_share_companies = {
            'å®¶é›»': [
                'ã‚½ãƒ‹ãƒ¼', 'ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯', 'ã‚·ãƒ£ãƒ¼ãƒ—', 'æ±èŠãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«', 'ä¸‰è±é›»æ©Ÿ',
                'æ—¥ç«‹ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ©ã‚¤ãƒ•ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚º', 'ä¸‰æ´‹é›»æ©Ÿ', 'ãƒ“ã‚¯ã‚¿ãƒ¼', 'ã‚¢ã‚¤ãƒ¯', 'èˆ¹äº•é›»æ©Ÿ'
            ],
            'åŠå°ä½“': [
                'æ±èŠãƒ¡ãƒ¢ãƒª', 'æ—¥ç«‹è£½ä½œæ‰€', 'ä¸‰è±é›»æ©Ÿ', 'NEC', 'å¯Œå£«é€š',
                'ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯', 'ã‚½ãƒ‹ãƒ¼', 'ãƒ«ãƒã‚µã‚¹ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹', 'ã‚·ãƒ£ãƒ¼ãƒ—', 'ãƒ­ãƒ¼ãƒ '
            ],
            'ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³': [
                'ã‚½ãƒ‹ãƒ¼Xperia', 'ã‚·ãƒ£ãƒ¼ãƒ—AQUOS', 'äº¬ã‚»ãƒ©', 'ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯', 'å¯Œå£«é€šarrows',
                'NEC', 'æ—¥ç«‹è£½ä½œæ‰€', 'ä¸‰è±é›»æ©Ÿ', 'æ±èŠ', 'ã‚«ã‚·ã‚ªè¨ˆç®—æ©Ÿ'
            ],
            'PC': [
                'ã‚½ãƒ‹ãƒ¼VAIO', 'NEC', 'å¯Œå£«é€š', 'æ±èŠdynabook', 'ã‚·ãƒ£ãƒ¼ãƒ—',
                'ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯', 'æ—¥ç«‹è£½ä½œæ‰€', 'ä¸‰è±é›»æ©Ÿ', 'ã‚«ã‚·ã‚ªè¨ˆç®—æ©Ÿ',
                'æ—¥æœ¬é›»æ°—ãƒ›ãƒ¼ãƒ ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹'
            ],
            'é€šä¿¡æ©Ÿå™¨': [
                'NEC', 'å¯Œå£«é€š', 'æ—¥ç«‹è£½ä½œæ‰€', 'ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯', 'ã‚·ãƒ£ãƒ¼ãƒ—',
                'ã‚½ãƒ‹ãƒ¼ã‚¨ãƒªã‚¯ã‚½ãƒ³', 'ä¸‰è±é›»æ©Ÿ', 'äº¬ã‚»ãƒ©', 'ã‚«ã‚·ã‚ªè¨ˆç®—æ©Ÿ', 'æ—¥æœ¬ç„¡ç·š'
            ]
        }
        
        # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        company_id = 1
        
        for category, sectors in [
            ('high_share', high_share_companies),
            ('declining', declining_companies),
            ('lost_share', lost_share_companies)
        ]:
            for sector, company_list in sectors.items():
                for company_name in company_list:
                    # ä¼æ¥­ã®è¨­ç«‹å¹´ãƒ»ä¸Šå ´å¹´ã‚’æ¨å®š
                    if category == 'high_share':
                        founded_year = 1950 + (company_id % 40)
                        data_start_year = max(1984, founded_year + 10)
                        data_end_year = 2024
                        status = 'active'
                    elif category == 'declining':
                        founded_year = 1945 + (company_id % 35)
                        data_start_year = max(1984, founded_year + 15)
                        data_end_year = 2024
                        status = 'active'
                    else:  # lost_share
                        founded_year = 1940 + (company_id % 50)
                        data_start_year = max(1984, founded_year + 20)
                        # ä¸€éƒ¨ä¼æ¥­ã¯æ¶ˆæ»…ãƒ»çµ±åˆ
                        if company_name in ['ä¸‰æ´‹é›»æ©Ÿ', 'ã‚¢ã‚¤ãƒ¯', 'æ—¥æœ¬é›»æ°—ãƒ›ãƒ¼ãƒ ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹']:
                            data_end_year = 2000 + (company_id % 20)
                            status = 'merged'
                        elif company_name in ['å¯Œå£«é€šarrows', 'ã‚½ãƒ‹ãƒ¼ã‚¨ãƒªã‚¯ã‚½ãƒ³']:
                            data_end_year = 2015 + (company_id % 8)
                            status = 'bankrupt'
                        else:
                            data_end_year = 2024
                            status = 'active'
                    
                    companies.append({
                        'company_id': company_id,
                        'company_name': company_name,
                        'market_category': category,
                        'market_sector': sector,
                        'founded_year': founded_year,
                        'data_start_year': data_start_year,
                        'data_end_year': data_end_year,
                        'current_status': status,
                        'observation_years': data_end_year - data_start_year + 1
                    })
                    company_id += 1
        
        df = pd.DataFrame(companies)
        self.logger.info(f"å®Œå…¨ä¼æ¥­ãƒªã‚¹ãƒˆç”Ÿæˆå®Œäº†: {len(df)}ç¤¾")
        return df
    
    def save_company_list(self, output_path: str = "data/companies_master.csv") -> bool:
        """ä¼æ¥­ãƒªã‚¹ãƒˆã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            df = self.generate_complete_company_list()
            
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            output_file = Path(output_path)
            output_file.parent.mkdir(parents=True, exist_ok=True)
            
            # CSVä¿å­˜
            df.to_csv(output_file, index=False, encoding='utf-8-sig')
            
            # çµ±è¨ˆæƒ…å ±å‡ºåŠ›
            print(f"\nğŸ“Š ä¼æ¥­ãƒªã‚¹ãƒˆçµ±è¨ˆ:")
            print(f"ç·ä¼æ¥­æ•°: {len(df)}")
            print(f"å¸‚å ´ã‚«ãƒ†ã‚´ãƒªåˆ¥:")
            print(df['market_category'].value_counts())
            print(f"\nä¼æ¥­ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥:")
            print(df['current_status'].value_counts())
            print(f"\nå¹³å‡è¦³æ¸¬å¹´æ•°: {df['observation_years'].mean():.1f}å¹´")
            
            self.logger.info(f"ä¼æ¥­ãƒªã‚¹ãƒˆCSVä¿å­˜å®Œäº†: {output_file}")
            return True
            
        except Exception as e:
            self.logger.error(f"ä¼æ¥­ãƒªã‚¹ãƒˆCSVä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False


if __name__ == "__main__":
    main()